{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aditya dhurandhar.JPG', 'Advait Shivaikar.JPG', 'Amit Kanse.JPG', 'Anjali.JPG', 'Anushka Gadgil.JPG', 'Arfat Lamboo.JPG', 'Asif.JPG', 'Chandraprakash Vishwakarma.JPG', 'Jagruti Sawalkar.JPG', 'Jasmeet Dhanota.JPG', 'Jasmit Hanspal.JPG', 'Jayesh.JPG', 'Kiran Patil.JPG', 'Kirtiraj Khape.JPG', 'Mayuresh.JPG', 'Mehtab Aalam.JPG', 'Neha Sutar.JPG', 'Onkar raut.JPG', 'Prajakta.JPG', 'Pranav Phale.JPG', 'Pranav Purushan.JPG', 'Pranita Jadhav.JPG', 'Pratima.jpg', 'Prithvi Shetty.JPG', 'Priya Jadhav.JPG', 'Reshma Sawant.JPG', 'Saarang Kulkarni.JPG', 'Sahil Kedari.JPG', 'Sangram Ghadage.JPG', 'Sheetal Patil.JPG', 'Shivam Yadav.JPG', 'Shivshankar Sahu.JPG', 'Shreyas Kulkarni.JPG', 'Shripad Joshi.JPG', 'Shubhangi B.JPG', 'Suraj Pal.JPG', 'Varad rane.JPG', 'Vinay Datir.JPG', 'Vinayak Mirjolkar.JPG', 'Vinit.JPG']\n",
      "['Aditya dhurandhar', 'Advait Shivaikar', 'Amit Kanse', 'Anjali', 'Anushka Gadgil', 'Arfat Lamboo', 'Asif', 'Chandraprakash Vishwakarma', 'Jagruti Sawalkar', 'Jasmeet Dhanota', 'Jasmit Hanspal', 'Jayesh', 'Kiran Patil', 'Kirtiraj Khape', 'Mayuresh', 'Mehtab Aalam', 'Neha Sutar', 'Onkar raut', 'Prajakta', 'Pranav Phale', 'Pranav Purushan', 'Pranita Jadhav', 'Pratima', 'Prithvi Shetty', 'Priya Jadhav', 'Reshma Sawant', 'Saarang Kulkarni', 'Sahil Kedari', 'Sangram Ghadage', 'Sheetal Patil', 'Shivam Yadav', 'Shivshankar Sahu', 'Shreyas Kulkarni', 'Shripad Joshi', 'Shubhangi B', 'Suraj Pal', 'Varad rane', 'Vinay Datir', 'Vinayak Mirjolkar', 'Vinit']\n",
      "Encoding Complete\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Attendance.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4e774848fcac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFILLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_COMPLEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mmarkAttendance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Webcam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4e774848fcac>\u001b[0m in \u001b[0;36mmarkAttendance\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#creates an excel file with the name of the identified student with date and timing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmarkAttendance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attendance.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mmyDataList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Attendance.csv'"
     ]
    }
   ],
   "source": [
    "#packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "path = 'ImagesAttendance'  #directory of students image data with 40 student images\n",
    "images = []               #creating the list of  students image path\n",
    "student_Names = []           #creating the list of  students name\n",
    "myList = os.listdir(path)    #listing out the files/folders in that path \n",
    "print(myList)\n",
    "\n",
    "\n",
    "\n",
    "#Looping over the path to grab the students name\n",
    "for cl in myList:\n",
    "    current_Img = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(current_Img)\n",
    "    student_Names.append(os.path.splitext(cl)[0]) #splitting the path and grabbing names, \n",
    "                                                  #eg: xyz.jpg, it splits into (xyz, .jpg)\n",
    "print(student_Names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#fuction for grabing the encodings of the images\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "\n",
    "\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#creates an excel file with the name of the identified student with date and timing \n",
    "def markAttendance(name):\n",
    "    with open('Attendance.csv', 'r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "\n",
    "\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "            if name not in nameList:\n",
    "                now = datetime.now()\n",
    "                dtString = now.strftime('%H:%M:%S')\n",
    "                f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "#### FOR CAPTURING SCREEN RATHER THAN WEBCAM\n",
    "# def captureScreen(bbox=(300,300,690+300,530+300)):\n",
    "#     capScr = np.array(ImageGrab.grab(bbox))\n",
    "#     capScr = cv2.cvtColor(capScr, cv2.COLOR_RGB2BGR)\n",
    "#     return capScr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encodeListKnown = findEncodings(images) #Grabbing the encodings of the faces\n",
    "print('Encoding Complete')\n",
    "\n",
    "\n",
    "\n",
    "#Below code captures and  turns the webcam on and starts to capture detect faces from the video frame\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success, img = cap.read()  #reads the frame and gives a boolean value, TRUE = frame gets captured\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #Resizing the images to 1/4th of its original size\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    \n",
    "    #Converting the image color from BGR to RGB as OpenCv reads image in BGR format\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Grabbing the co-ordinates of the the detected face\n",
    "    facesCurrentFrame = face_recognition.face_locations(imgS)\n",
    "    \n",
    "    #Grabbing the encoding of that particular image    \n",
    "    encodesCurrentFrame = face_recognition.face_encodings(imgS, facesCurrentFrame)\n",
    "    \n",
    "    \n",
    "    #Looping over the encodings and face location for the comparison pupose\n",
    "    for encodeFace, faceLoc in zip(encodesCurrentFrame, facesCurrentFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        \n",
    "        #Images with unique distance\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        # print(faceDis)\n",
    "        \n",
    "        #taking the only minimum distance \n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "            name = student_Names[matchIndex].upper() #change the string to UpperCase\n",
    "            # print(name)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #Code for creating the bounding box with the name around the face\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "            markAttendance(name)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
